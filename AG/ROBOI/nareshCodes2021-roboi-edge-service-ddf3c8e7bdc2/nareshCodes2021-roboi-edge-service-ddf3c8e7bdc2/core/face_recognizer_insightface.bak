import os
import cv2
import numpy as np
from insightface.app import FaceAnalysis
from core.logger import get_app_logger

logger = get_app_logger("face-id")

class RoboFaceID:
    def __init__(self, model_root="models/insightface"):
        """
        Initializes the InsightFace analysis engine.
        """
        logger.info(f"Initializing InsightFace (root: {model_root})")
        # Ensure model directory exists
        os.makedirs(model_root, exist_ok=True)
        
        # Initialize FaceAnalysis
        # buffalo_l is the default model pack
        try:
            self.app = FaceAnalysis(name='buffalo_l', root=model_root, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
            # Lower det_thresh to 0.4 to catch more faces in crops
            self.app.prepare(ctx_id=0, det_size=(640, 640), det_thresh=0.4)
        except Exception as e:
            logger.error(f"Failed to initialize FaceAnalysis: {e}")
            self.app = None
        
        self.face_db = []
        self.last_frame_id = None
        self.last_faces = []
        
        if self.app:
            self.load_database()

    def load_database(self, faces_path="data/faces"):
        """
        Loads reference images and generates embeddings.
        """
        if not os.path.exists(faces_path):
            logger.warning(f"Faces database path not found: {faces_path}")
            return

        # Sort filenames for consistent ID assignment
        files = sorted([f for f in os.listdir(faces_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        
        seen_names = {}
        next_id = 1

        for filename in files:
            name = os.path.splitext(filename)[0].lower()
            if name not in seen_names:
                seen_names[name] = next_id
                next_id += 1
            
            p_id = seen_names[name]
            img_path = os.path.join(faces_path, filename)
            img = cv2.imread(img_path)
            
            if img is None:
                logger.error(f"Failed to load image: {img_path}")
                continue
            
            faces = self.app.get(img)
            if len(faces) > 0:
                face = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)[0]
                self.face_db.append({
                    "name": name,
                    "id": p_id,
                    "embedding": face.normed_embedding
                })
                logger.info(f"Registered: {name} (ID: {p_id})")
            else:
                logger.warning(f"No face in {img_path}. Skipping.")

    def recognize(self, frame, bbox, frame_id, threshold=0.5):
        """
        Recognizes a face by cropping the provided bbox area first.
        Optimized for Person boxes: extracts a square crop and identifies the face.
        """
        if self.app is None:
            return "EngineError", 0.0

        try:
            h, w, _ = frame.shape
            x1, y1, x2, y2 = map(int, bbox)
            
            # --- 1. Optimized Square Cropping ---
            bw = x2 - x1
            bh = y2 - y1
            
            # Estimate head center: Top 15% of the body
            head_cx = x1 + (bw / 2)
            head_cy = y1 + (bh * 0.15)
            
            # Square size: 120% of body width or 45% of body height, whichever is larger.
            square_size = int(max(bw * 1.2, bh * 0.45))
            
            # Calculate square bounds centered on head_cx, head_cy
            cx1 = int(head_cx - (square_size / 2))
            cy1 = int(head_cy - (square_size * 0.45)) # Offset slightly up for forehead
            cx2 = cx1 + square_size
            cy2 = cy1 + square_size
            
            # Clamp to image bounds
            cx1, cy1 = max(0, cx1), max(0, cy1)
            cx2, cy2 = min(w, cx2), min(h, cy2)
            
            person_crop = frame[cy1:cy2, cx1:cx2]
            
            if person_crop.size == 0 or person_crop.shape[0] < 10 or person_crop.shape[1] < 10:
                # Fallback to simple upper body
                person_crop = frame[max(0, y1):min(h, y1 + int(bh*0.6)), max(0, x1):min(w, x2)]

            if person_crop.size == 0:
                return "Stranger", 1.0, 0

            # --- 2. Run InsightFace on the CROP ---
            faces = self.app.get(person_crop)
            
            if not faces:
                # Fallback: Body crop
                person_crop = frame[max(0, y1):min(h, y2), max(0, x1):min(w, x2)]
                faces = self.app.get(person_crop)
                
            if not faces:
                return "Stranger", 1.0, 0

            # Identify and Match
            best_face = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)[0]
            
            emb = best_face.normed_embedding
            best_match = "Stranger"
            best_match_id = 0
            max_sim = 0.0
            
            for ref in self.face_db:
                sim = float(np.dot(emb, ref["embedding"]))
                if sim > max_sim:
                    max_sim = sim
                    if sim >= threshold:
                        best_match = ref["name"]
                        best_match_id = ref["id"]
            
            # Decision Logic for Logging
            status = "MATCH" if best_match != "Stranger" else "STRANGER"
            logger.info(f"Cropped Recognition: {status} | Candidate='{best_match}', Score={max_sim:.4f}")
            
            # If it's a stranger, we follow user request: identity: stranger, confidence: 1
            if best_match == "Stranger":
                return "Stranger", 1.0, 0
            
            return best_match, max_sim, best_match_id

        except Exception as e:
            logger.error(f"Cropped Recognition Error: {e}")
            return "Error", 0.0, -1