{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî• YOLO11 Fire, Smoke & Fighting Detection Training Notebook\n",
                "\n",
                "## Complete End-to-End Training Pipeline for InvEye\n",
                "\n",
                "This notebook provides a comprehensive training pipeline for detecting:\n",
                "- **Fire** üî•\n",
                "- **Smoke** üí®\n",
                "- **Fighting/Violence** üëä\n",
                "\n",
                "**Target Platform:** NVIDIA Jetson Orin Nano with DeepStream\n",
                "\n",
                "---\n",
                "\n",
                "### üìã Table of Contents\n",
                "1. [Environment Setup](#1-environment-setup)\n",
                "2. [Dataset Download from Roboflow](#2-dataset-download)\n",
                "3. [Dataset Exploration](#3-dataset-exploration)\n",
                "4. [Model Training](#4-model-training)\n",
                "5. [Model Validation](#5-model-validation)\n",
                "6. [Model Testing & Inference](#6-inference)\n",
                "7. [Export for Jetson Deployment](#7-export)\n",
                "8. [Download Trained Model](#8-download)\n",
                "\n",
                "---\n",
                "\n",
                "> ‚ö†Ô∏è **IMPORTANT**: Run cells in order! Each section depends on the previous one."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Environment Setup <a name=\"1-environment-setup\"></a>\n",
                "\n",
                "### 1.1 Check GPU Availability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if GPU is available\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\n‚úÖ PyTorch Version: {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU Device: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Install Required Packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install ultralytics (YOLO11) and roboflow\n",
                "!pip install -q ultralytics>=8.3.0\n",
                "!pip install -q roboflow\n",
                "!pip install -q opencv-python-headless\n",
                "!pip install -q supervision\n",
                "\n",
                "print(\"\\n‚úÖ All packages installed successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify ultralytics installation\n",
                "from ultralytics import YOLO\n",
                "import ultralytics\n",
                "\n",
                "print(f\"‚úÖ Ultralytics Version: {ultralytics.__version__}\")\n",
                "ultralytics.checks()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import shutil\n",
                "import yaml\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "from IPython.display import display, Image as IPImage, clear_output\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "random.seed(42)\n",
                "np.random.seed(42)\n",
                "torch.manual_seed(42)\n",
                "\n",
                "# Initialize global variables\n",
                "USE_CUSTOM_IMAGES = False\n",
                "DATASET_PATH = None\n",
                "\n",
                "print(\"‚úÖ All libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Dataset Download from Roboflow <a name=\"2-dataset-download\"></a>\n",
                "\n",
                "We'll download pre-annotated datasets for fire, smoke, and fighting detection from Roboflow.\n",
                "\n",
                "> ‚ö†Ô∏è **Important:** Get your free API key from [Roboflow](https://roboflow.com/)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from roboflow import Roboflow\n",
                "\n",
                "# ========================================\n",
                "# üîë ENTER YOUR ROBOFLOW API KEY HERE\n",
                "# ========================================\n",
                "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your API key\n",
                "\n",
                "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
                "print(\"‚úÖ Connected to Roboflow!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Download Fire & Smoke Dataset\n",
                "\n",
                "We'll use a high-quality fire and smoke dataset from Roboflow Universe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Option 1: Fire and Smoke Detection Dataset\n",
                "# This is a popular dataset with good annotations\n",
                "\n",
                "try:\n",
                "    # Download fire detection dataset\n",
                "    project = rf.workspace(\"roboflow-universe-projects\").project(\"fire-detection-o7knn\")\n",
                "    fire_dataset = project.version(16).download(\"yolov8\")\n",
                "    DATASET_PATH = fire_dataset.location\n",
                "    print(f\"\\n‚úÖ Fire dataset downloaded to: {DATASET_PATH}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Error downloading dataset: {e}\")\n",
                "    print(\"\\nüí° Try the alternative dataset in the next cell.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Alternative: Another fire/smoke dataset (run if above doesn't work)\n",
                "# Only run this cell if the above cell failed\n",
                "\n",
                "if DATASET_PATH is None:\n",
                "    try:\n",
                "        project = rf.workspace(\"-jwzpw\").project(\"continuous_fire\")\n",
                "        fire_dataset = project.version(6).download(\"yolov8\")\n",
                "        DATASET_PATH = fire_dataset.location\n",
                "        print(f\"\\n‚úÖ Fire dataset downloaded to: {DATASET_PATH}\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error: {e}\")\n",
                "else:\n",
                "    print(\"‚úÖ Dataset already downloaded. Skipping alternative.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Download Fighting/Violence Dataset (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download fighting/violence detection dataset\n",
                "# This is optional - run only if you want to detect fighting as well\n",
                "\n",
                "INCLUDE_FIGHTING = False  # Set to True to include fighting detection\n",
                "\n",
                "if INCLUDE_FIGHTING:\n",
                "    try:\n",
                "        project = rf.workspace(\"violence-detection\").project(\"fight-detection-dataset\")\n",
                "        fight_dataset = project.version(1).download(\"yolov8\")\n",
                "        print(f\"\\n‚úÖ Fighting dataset downloaded to: {fight_dataset.location}\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Could not download fighting dataset: {e}\")\n",
                "        print(\"Continuing with fire detection only...\")\n",
                "        INCLUDE_FIGHTING = False\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Skipping fighting dataset (set INCLUDE_FIGHTING = True to include)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Alternative: Use Your Own Images\n",
                "\n",
                "If you have your own fire incident images, use this section to set up the dataset structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# ALTERNATIVE: Using Your Own Custom Images\n",
                "# ============================================\n",
                "\n",
                "# Set to True ONLY if you want to use your own images\n",
                "USE_CUSTOM_IMAGES = False\n",
                "\n",
                "if USE_CUSTOM_IMAGES:\n",
                "    # Create dataset directory structure\n",
                "    custom_dataset_path = \"/content/custom_fire_dataset\"\n",
                "    \n",
                "    for split in ['train', 'valid', 'test']:\n",
                "        os.makedirs(f\"{custom_dataset_path}/images/{split}\", exist_ok=True)\n",
                "        os.makedirs(f\"{custom_dataset_path}/labels/{split}\", exist_ok=True)\n",
                "    \n",
                "    print(\"\\nüìÅ Created dataset structure:\")\n",
                "    print(f\"   {custom_dataset_path}/\")\n",
                "    print(\"   ‚îú‚îÄ‚îÄ images/\")\n",
                "    print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ train/   <- Put 70% of your images here\")\n",
                "    print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ valid/   <- Put 20% of your images here\")\n",
                "    print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ test/    <- Put 10% of your images here\")\n",
                "    print(\"   ‚îî‚îÄ‚îÄ labels/\")\n",
                "    print(\"       ‚îú‚îÄ‚îÄ train/   <- Corresponding .txt label files\")\n",
                "    print(\"       ‚îú‚îÄ‚îÄ valid/\")\n",
                "    print(\"       ‚îî‚îÄ‚îÄ test/\")\n",
                "    \n",
                "    # Create data.yaml\n",
                "    data_yaml = {\n",
                "        'path': custom_dataset_path,\n",
                "        'train': 'images/train',\n",
                "        'val': 'images/valid',\n",
                "        'test': 'images/test',\n",
                "        'names': {\n",
                "            0: 'fire',\n",
                "            1: 'smoke'\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    with open(f\"{custom_dataset_path}/data.yaml\", 'w') as f:\n",
                "        yaml.dump(data_yaml, f)\n",
                "    \n",
                "    DATASET_PATH = custom_dataset_path\n",
                "    print(f\"\\n‚úÖ Created data.yaml at {custom_dataset_path}/data.yaml\")\n",
                "    print(\"\\n‚ö†Ô∏è Remember: Each image needs a corresponding .txt label file!\")\n",
                "    print(\"   Format: class_id x_center y_center width height (normalized 0-1)\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Using Roboflow dataset (not custom images)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Dataset Exploration <a name=\"3-dataset-exploration\"></a>\n",
                "\n",
                "> ‚ö†Ô∏è **Make sure Section 2.1 ran successfully before continuing!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify dataset path is set\n",
                "if DATASET_PATH is None:\n",
                "    print(\"‚ùå ERROR: DATASET_PATH is not set!\")\n",
                "    print(\"\")\n",
                "    print(\"Please go back and run Section 2.1 (Download Fire & Smoke Dataset) first.\")\n",
                "    print(\"Make sure the download completed successfully.\")\n",
                "    raise ValueError(\"Dataset not downloaded. Run Section 2.1 first.\")\n",
                "else:\n",
                "    print(f\"‚úÖ Dataset Path: {DATASET_PATH}\")\n",
                "    print(\"\\nüìä Dataset Contents:\")\n",
                "    !ls -la {DATASET_PATH}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and display data.yaml\n",
                "data_yaml_path = f\"{DATASET_PATH}/data.yaml\"\n",
                "\n",
                "with open(data_yaml_path, 'r') as f:\n",
                "    data_config = yaml.safe_load(f)\n",
                "\n",
                "print(\"üìã Dataset Configuration (data.yaml):\")\n",
                "print(\"=\" * 50)\n",
                "for key, value in data_config.items():\n",
                "    print(f\"  {key}: {value}\")\n",
                "\n",
                "# Get class names\n",
                "class_names = data_config.get('names', {})\n",
                "num_classes = len(class_names)\n",
                "print(f\"\\nüìä Number of Classes: {num_classes}\")\n",
                "print(f\"üìä Class Names: {class_names}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count images in each split\n",
                "def count_images(path):\n",
                "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
                "    count = 0\n",
                "    for ext in extensions:\n",
                "        count += len(glob.glob(os.path.join(path, ext)))\n",
                "    return count\n",
                "\n",
                "# Handle different folder structures\n",
                "train_images = f\"{DATASET_PATH}/train/images\" if os.path.exists(f\"{DATASET_PATH}/train/images\") else f\"{DATASET_PATH}/images/train\"\n",
                "valid_images = f\"{DATASET_PATH}/valid/images\" if os.path.exists(f\"{DATASET_PATH}/valid/images\") else f\"{DATASET_PATH}/images/valid\"\n",
                "test_images = f\"{DATASET_PATH}/test/images\" if os.path.exists(f\"{DATASET_PATH}/test/images\") else f\"{DATASET_PATH}/images/test\"\n",
                "\n",
                "print(\"üìä Dataset Statistics:\")\n",
                "print(\"=\" * 50)\n",
                "if os.path.exists(train_images):\n",
                "    print(f\"  Training Images:   {count_images(train_images)}\")\n",
                "if os.path.exists(valid_images):\n",
                "    print(f\"  Validation Images: {count_images(valid_images)}\")\n",
                "if os.path.exists(test_images):\n",
                "    print(f\"  Test Images:       {count_images(test_images)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample images from dataset\n",
                "def visualize_samples(image_folder, num_samples=6):\n",
                "    \"\"\"Display sample images from the dataset\"\"\"\n",
                "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
                "    all_images = []\n",
                "    for ext in extensions:\n",
                "        all_images.extend(glob.glob(os.path.join(image_folder, ext)))\n",
                "    \n",
                "    if not all_images:\n",
                "        print(f\"No images found in {image_folder}\")\n",
                "        return\n",
                "    \n",
                "    samples = random.sample(all_images, min(num_samples, len(all_images)))\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for idx, img_path in enumerate(samples):\n",
                "        if idx >= 6:\n",
                "            break\n",
                "        img = Image.open(img_path)\n",
                "        axes[idx].imshow(img)\n",
                "        axes[idx].set_title(os.path.basename(img_path)[:30], fontsize=8)\n",
                "        axes[idx].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.suptitle(\"üî• Sample Training Images\", fontsize=14, y=1.02)\n",
                "    plt.show()\n",
                "\n",
                "print(\"üñºÔ∏è Sample Training Images:\")\n",
                "visualize_samples(train_images)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Model Training <a name=\"4-model-training\"></a>\n",
                "\n",
                "### 4.1 Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# üîß TRAINING CONFIGURATION\n",
                "# ============================================\n",
                "\n",
                "# Model Selection (choose one)\n",
                "# Options: 'yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt'\n",
                "# Smaller = Faster but less accurate | Larger = Slower but more accurate\n",
                "MODEL_SIZE = 'yolo11n.pt'  # nano - best for Jetson\n",
                "\n",
                "# Training Parameters\n",
                "EPOCHS = 100          # Number of training epochs (increase for better results)\n",
                "BATCH_SIZE = 16       # Batch size (reduce if OOM error)\n",
                "IMAGE_SIZE = 640      # Input image size\n",
                "PATIENCE = 50         # Early stopping patience\n",
                "WORKERS = 4           # Number of data loading workers\n",
                "\n",
                "# Optimization\n",
                "OPTIMIZER = 'auto'    # Options: 'SGD', 'Adam', 'AdamW', 'auto'\n",
                "LR0 = 0.01           # Initial learning rate\n",
                "LRF = 0.01           # Final learning rate factor\n",
                "\n",
                "# Augmentation (data augmentation settings)\n",
                "AUGMENT = True\n",
                "MOSAIC = 1.0         # Mosaic augmentation probability\n",
                "MIXUP = 0.0          # Mixup augmentation probability\n",
                "COPY_PASTE = 0.0     # Copy-paste augmentation probability\n",
                "\n",
                "# Project Settings\n",
                "PROJECT_NAME = 'fire_detection'\n",
                "EXPERIMENT_NAME = 'yolo11_fire_smoke'\n",
                "\n",
                "print(\"‚úÖ Training configuration set!\")\n",
                "print(f\"\\nüìã Configuration Summary:\")\n",
                "print(f\"   Model: {MODEL_SIZE}\")\n",
                "print(f\"   Epochs: {EPOCHS}\")\n",
                "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"   Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
                "print(f\"   Dataset: {DATASET_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Start Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pre-trained YOLO11 model\n",
                "model = YOLO(MODEL_SIZE)\n",
                "\n",
                "print(f\"‚úÖ Loaded pre-trained {MODEL_SIZE} model\")\n",
                "print(f\"\\nüöÄ Starting training...\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "results = model.train(\n",
                "    data=data_yaml_path,\n",
                "    epochs=EPOCHS,\n",
                "    batch=BATCH_SIZE,\n",
                "    imgsz=IMAGE_SIZE,\n",
                "    patience=PATIENCE,\n",
                "    workers=WORKERS,\n",
                "    optimizer=OPTIMIZER,\n",
                "    lr0=LR0,\n",
                "    lrf=LRF,\n",
                "    augment=AUGMENT,\n",
                "    mosaic=MOSAIC,\n",
                "    mixup=MIXUP,\n",
                "    copy_paste=COPY_PASTE,\n",
                "    project=PROJECT_NAME,\n",
                "    name=EXPERIMENT_NAME,\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    verbose=True,\n",
                "    seed=42,\n",
                "    device=0,  # Use GPU 0\n",
                "    cache=True,  # Cache images for faster training\n",
                "    amp=True,  # Use automatic mixed precision\n",
                "    plots=True,  # Generate training plots\n",
                "    save=True,\n",
                "    save_period=10  # Save checkpoint every 10 epochs\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"‚úÖ Training completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 View Training Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training results\n",
                "RESULTS_DIR = f\"{PROJECT_NAME}/{EXPERIMENT_NAME}\"\n",
                "\n",
                "print(f\"üìÅ Results saved to: {RESULTS_DIR}\")\n",
                "print(\"\\nüìä Training artifacts:\")\n",
                "!ls -la {RESULTS_DIR}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training curves\n",
                "results_png = f\"{RESULTS_DIR}/results.png\"\n",
                "if os.path.exists(results_png):\n",
                "    print(\"üìà Training Curves:\")\n",
                "    display(IPImage(filename=results_png))\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Results image not found. Training may still be in progress.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display confusion matrix\n",
                "confusion_matrix_png = f\"{RESULTS_DIR}/confusion_matrix.png\"\n",
                "if os.path.exists(confusion_matrix_png):\n",
                "    print(\"üìä Confusion Matrix:\")\n",
                "    display(IPImage(filename=confusion_matrix_png))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display sample predictions from validation\n",
                "val_batch_png = f\"{RESULTS_DIR}/val_batch0_pred.png\"\n",
                "if os.path.exists(val_batch_png):\n",
                "    print(\"üîç Sample Validation Predictions:\")\n",
                "    display(IPImage(filename=val_batch_png))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Model Validation <a name=\"5-model-validation\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best trained model\n",
                "BEST_MODEL_PATH = f\"{RESULTS_DIR}/weights/best.pt\"\n",
                "\n",
                "if os.path.exists(BEST_MODEL_PATH):\n",
                "    best_model = YOLO(BEST_MODEL_PATH)\n",
                "    print(f\"‚úÖ Loaded best model from: {BEST_MODEL_PATH}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Best model not found. Using last trained model.\")\n",
                "    best_model = model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate the model\n",
                "print(\"üîç Running validation...\")\n",
                "val_results = best_model.val(\n",
                "    data=data_yaml_path,\n",
                "    batch=BATCH_SIZE,\n",
                "    imgsz=IMAGE_SIZE,\n",
                "    split='val',\n",
                "    plots=True,\n",
                "    save_json=True\n",
                ")\n",
                "\n",
                "print(\"\\nüìä Validation Metrics:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"  mAP50:      {val_results.box.map50:.4f}\")\n",
                "print(f\"  mAP50-95:   {val_results.box.map:.4f}\")\n",
                "print(f\"  Precision:  {val_results.box.mp:.4f}\")\n",
                "print(f\"  Recall:     {val_results.box.mr:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class metrics\n",
                "print(\"\\nüìä Per-Class Performance:\")\n",
                "print(\"=\" * 50)\n",
                "for i, class_name in enumerate(class_names.values()):\n",
                "    if i < len(val_results.box.ap50):\n",
                "        print(f\"  {class_name}:\")\n",
                "        print(f\"    - AP50: {val_results.box.ap50[i]:.4f}\")\n",
                "        print(f\"    - AP:   {val_results.box.ap[i]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Model Testing & Inference <a name=\"6-inference\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on sample images\n",
                "print(\"üîç Running inference on test images...\")\n",
                "\n",
                "# Get test images\n",
                "test_folder = test_images if os.path.exists(test_images) else valid_images\n",
                "test_image_files = glob.glob(os.path.join(test_folder, '*.jpg')) + \\\n",
                "                   glob.glob(os.path.join(test_folder, '*.png'))\n",
                "\n",
                "if test_image_files:\n",
                "    # Run inference on a few test images\n",
                "    sample_images = random.sample(test_image_files, min(4, len(test_image_files)))\n",
                "    \n",
                "    predictions = best_model.predict(\n",
                "        source=sample_images,\n",
                "        conf=0.25,\n",
                "        iou=0.45,\n",
                "        save=True,\n",
                "        project=PROJECT_NAME,\n",
                "        name='test_predictions'\n",
                "    )\n",
                "    \n",
                "    print(f\"\\n‚úÖ Predictions saved to: {PROJECT_NAME}/test_predictions\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No test images found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display prediction results\n",
                "pred_folder = f\"{PROJECT_NAME}/test_predictions\"\n",
                "if os.path.exists(pred_folder):\n",
                "    pred_images = glob.glob(os.path.join(pred_folder, '*.jpg')) + \\\n",
                "                  glob.glob(os.path.join(pred_folder, '*.png'))\n",
                "    \n",
                "    if pred_images:\n",
                "        fig, axes = plt.subplots(1, min(4, len(pred_images)), figsize=(20, 5))\n",
                "        if len(pred_images) == 1:\n",
                "            axes = [axes]\n",
                "        \n",
                "        for idx, img_path in enumerate(pred_images[:4]):\n",
                "            img = Image.open(img_path)\n",
                "            axes[idx].imshow(img)\n",
                "            axes[idx].set_title(f\"Prediction {idx+1}\")\n",
                "            axes[idx].axis('off')\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.suptitle(\"üî• Fire Detection Predictions\", fontsize=14, y=1.02)\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Export for Jetson Deployment <a name=\"7-export\"></a>\n",
                "\n",
                "Export the trained model in various formats for deployment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX (for DeepStream and general deployment)\n",
                "print(\"üì¶ Exporting model to ONNX format...\")\n",
                "\n",
                "onnx_path = best_model.export(\n",
                "    format='onnx',\n",
                "    imgsz=IMAGE_SIZE,\n",
                "    half=False,\n",
                "    simplify=True,\n",
                "    opset=12\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úÖ ONNX model exported to: {onnx_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary of all exported files\n",
                "print(\"\\nüì¶ Exported Model Files:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "weights_dir = f\"{RESULTS_DIR}/weights\"\n",
                "if os.path.exists(weights_dir):\n",
                "    for file in os.listdir(weights_dir):\n",
                "        filepath = os.path.join(weights_dir, file)\n",
                "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
                "        print(f\"  üìÑ {file} ({size_mb:.2f} MB)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Download Trained Model <a name=\"8-download\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a zip file with all trained models\n",
                "import zipfile\n",
                "\n",
                "zip_filename = 'fire_detection_models.zip'\n",
                "\n",
                "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
                "    # Add best.pt\n",
                "    if os.path.exists(f\"{weights_dir}/best.pt\"):\n",
                "        zipf.write(f\"{weights_dir}/best.pt\", 'best.pt')\n",
                "    \n",
                "    # Add last.pt\n",
                "    if os.path.exists(f\"{weights_dir}/last.pt\"):\n",
                "        zipf.write(f\"{weights_dir}/last.pt\", 'last.pt')\n",
                "    \n",
                "    # Add ONNX if exists\n",
                "    onnx_file = f\"{weights_dir}/best.onnx\"\n",
                "    if os.path.exists(onnx_file):\n",
                "        zipf.write(onnx_file, 'best.onnx')\n",
                "    \n",
                "    # Add results\n",
                "    if os.path.exists(f\"{RESULTS_DIR}/results.png\"):\n",
                "        zipf.write(f\"{RESULTS_DIR}/results.png\", 'training_results.png')\n",
                "    \n",
                "    # Add data.yaml for reference\n",
                "    zipf.write(data_yaml_path, 'data.yaml')\n",
                "\n",
                "print(f\"\\n‚úÖ Created: {zip_filename}\")\n",
                "print(f\"   Size: {os.path.getsize(zip_filename) / (1024 * 1024):.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download the zip file (for Google Colab)\n",
                "from google.colab import files\n",
                "\n",
                "print(\"üì• Downloading trained models...\")\n",
                "files.download(zip_filename)\n",
                "print(\"\\n‚úÖ Download started!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Alternative: Download individual files\n",
                "print(\"üì• Download individual files:\")\n",
                "print(\"\\n1. Best Model (PyTorch):\")\n",
                "files.download(f\"{weights_dir}/best.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üéâ Training Complete!\n",
                "\n",
                "### Summary\n",
                "\n",
                "You now have a trained YOLO11 fire detection model. Here's what was created:\n",
                "\n",
                "| File | Description | Use Case |\n",
                "|------|-------------|----------|\n",
                "| `best.pt` | Best performing model | General PyTorch inference |\n",
                "| `last.pt` | Last epoch model | Backup/resume training |\n",
                "| `best.onnx` | ONNX format | Cross-platform deployment |\n",
                "\n",
                "### Next Steps for Jetson Deployment\n",
                "\n",
                "1. **Copy `best.pt` to your Jetson device**\n",
                "2. **Convert to TensorRT on Jetson** (for best performance):\n",
                "   ```bash\n",
                "   yolo export model=best.pt format=engine device=0 half=True\n",
                "   ```\n",
                "3. **Integrate with DeepStream** using the generated `.engine` file\n",
                "\n",
                "### Model Performance Tips\n",
                "\n",
                "- If accuracy is low, try:\n",
                "  - Training for more epochs (200-300)\n",
                "  - Using a larger model (`yolo11s.pt` or `yolo11m.pt`)\n",
                "  - Adding more training data\n",
                "  - Fine-tuning augmentation parameters\n",
                "\n",
                "- If inference is slow on Jetson:\n",
                "  - Use `yolo11n.pt` (nano) model\n",
                "  - Enable FP16 (`half=True`)\n",
                "  - Reduce input size to 416 or 320"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}