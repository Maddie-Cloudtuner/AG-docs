{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî•üëäüí®üë§ Unified YOLO11n Model: Complete Petrol Pump Detection\n",
                "\n",
                "> **Purpose**: Train ONE model for all petrol pump safety detections\n",
                "> \n",
                "> **Target**: Jetson Orin Nano CCTV Monitoring\n",
                "> \n",
                "> **Base Model**: YOLO11n (edge-optimized)\n",
                "\n",
                "## Detection Classes:\n",
                "| ID | Class | Priority | Use Case |\n",
                "|---|-------|----------|----------|\n",
                "| 0 | person | üî¥ High | Customer/employee tracking |\n",
                "| 1 | fire | üî¥ Critical | Fuel ignition detection |\n",
                "| 2 | smoke | üî¥ Critical | Early fire warning |\n",
                "| 3 | violence | üü° Important | Security incidents |\n",
                "| 4 | cigarette | üî¥ Critical | Ignition source at pump |\n",
                "\n",
                "## Data Sources:\n",
                "- **Fire**: FASDD Dataset (same as ProFSAM-Fire-Detector model)\n",
                "- **Violence**: Roboflow datasets (same source as fight_detection_yolov8)\n",
                "- **Person**: COCO person subset + custom person detection\n",
                "- **Cigarette**: Roboflow smoking detection datasets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install ultralytics>=8.3.0 roboflow gdown kaggle -q\n",
                "\n",
                "# Verify installation\n",
                "import ultralytics\n",
                "ultralytics.checks()\n",
                "print(f\"‚úÖ Ultralytics version: {ultralytics.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import yaml\n",
                "import json\n",
                "from pathlib import Path\n",
                "from roboflow import Roboflow\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Create working directories\n",
                "BASE_DIR = Path('/content/unified_detection')\n",
                "DATASETS_DIR = BASE_DIR / 'datasets'\n",
                "MERGED_DIR = BASE_DIR / 'merged_dataset'\n",
                "MODELS_DIR = BASE_DIR / 'trained_models'\n",
                "\n",
                "for d in [DATASETS_DIR, MERGED_DIR, MODELS_DIR]:\n",
                "    d.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"‚úÖ Working directory: {BASE_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Configure Datasets\n",
                "\n",
                "### Dataset Sources:\n",
                "1. **FASDD (Fire & Smoke Detection Dataset)** - Used by ProFSAM-Fire-Detector\n",
                "2. **Violence Detection** - Similar to Musawer14/fight_detection_yolov8 training data\n",
                "3. **Person Detection** - COCO person subset + Roboflow person datasets\n",
                "4. **Cigarette/Smoking Detection** - Roboflow smoking datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Configure Roboflow API Key { display-mode: \"form\" }\n",
                "# Get your free API key from https://roboflow.com/\n",
                "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # @param {type:\"string\"}\n",
                "\n",
                "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
                "print(\"‚úÖ Roboflow configured\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# TARGET UNIFIED CLASSES (5 classes total)\n",
                "# ============================================\n",
                "UNIFIED_CLASSES = ['person', 'fire', 'smoke', 'violence', 'cigarette']\n",
                "\n",
                "# Dataset configurations - curated for petrol pump monitoring\n",
                "# Sources aligned with HuggingFace models you referenced\n",
                "DATASETS = {\n",
                "    # Person Detection - critical for customer/employee tracking\n",
                "    'person': {\n",
                "        'workspace': 'roboflow-100',\n",
                "        'project': 'people-detection-general',\n",
                "        'version': 1,\n",
                "        'class_mapping': {\n",
                "            'person': 'person', 'Person': 'person', \n",
                "            'people': 'person', 'human': 'person'\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    # Fire & Smoke - aligned with FASDD dataset used by ProFSAM-Fire-Detector\n",
                "    'fire_smoke': {\n",
                "        'workspace': 'fire-detection-kbsxn',\n",
                "        'project': 'fire-detection-qagzv',\n",
                "        'version': 2,\n",
                "        'class_mapping': {\n",
                "            'fire': 'fire', 'Fire': 'fire', 'flame': 'fire',\n",
                "            'smoke': 'smoke', 'Smoke': 'smoke'\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    # Additional fire dataset for better coverage\n",
                "    'fire_smoke_2': {\n",
                "        'workspace': 'fire-smoke-detection',\n",
                "        'project': 'fire-and-smoke-xspvt',\n",
                "        'version': 1,\n",
                "        'class_mapping': {\n",
                "            'fire': 'fire', 'Fire': 'fire',\n",
                "            'smoke': 'smoke', 'Smoke': 'smoke'\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    # Violence Detection - aligned with fight_detection_yolov8 training approach\n",
                "    'violence': {\n",
                "        'workspace': 'securityviolence',\n",
                "        'project': 'violence-detection-bxcxf',\n",
                "        'version': 1,\n",
                "        'class_mapping': {\n",
                "            'violence': 'violence', 'Violence': 'violence',\n",
                "            'fight': 'violence', 'Fight': 'violence',\n",
                "            'fighting': 'violence'\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    # Additional violence dataset for better coverage\n",
                "    'violence_2': {\n",
                "        'workspace': 'jaishreeram-uqqfn',\n",
                "        'project': 'violence_maksad',\n",
                "        'version': 1,\n",
                "        'class_mapping': {\n",
                "            'violence': 'violence', 'Violence': 'violence'\n",
                "        }\n",
                "    },\n",
                "    \n",
                "    # Cigarette/Smoking Detection - critical for petrol pumps\n",
                "    'smoking': {\n",
                "        'workspace': 'smoker-detection',\n",
                "        'project': 'smoker',\n",
                "        'version': 1,\n",
                "        'class_mapping': {\n",
                "            'smoker': 'cigarette', 'smoking': 'cigarette',\n",
                "            'cigarette': 'cigarette', 'Cigarette': 'cigarette'\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "print(f\"üéØ Target classes: {UNIFIED_CLASSES}\")\n",
                "print(f\"üì¶ Datasets to download: {len(DATASETS)}\")\n",
                "for name in DATASETS:\n",
                "    print(f\"   - {name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def download_dataset(name, config):\n",
                "    \"\"\"Download a dataset from Roboflow\"\"\"\n",
                "    try:\n",
                "        print(f\"\\nüì• Downloading {name}...\")\n",
                "        project = rf.workspace(config['workspace']).project(config['project'])\n",
                "        dataset = project.version(config['version']).download(\n",
                "            \"yolov8\",\n",
                "            location=str(DATASETS_DIR / name)\n",
                "        )\n",
                "        print(f\"‚úÖ Downloaded: {name}\")\n",
                "        return True\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Failed {name}: {e}\")\n",
                "        return False\n",
                "\n",
                "# Download all datasets\n",
                "print(\"=\"*50)\n",
                "print(\"DOWNLOADING DATASETS\")\n",
                "print(\"=\"*50)\n",
                "for name, config in DATASETS.items():\n",
                "    download_dataset(name, config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Download Additional Person Dataset (COCO subset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download COCO person subset for robust person detection\n",
                "# This ensures we have high-quality person annotations\n",
                "\n",
                "import urllib.request\n",
                "import zipfile\n",
                "\n",
                "def download_coco_person_subset():\n",
                "    \"\"\"Download a curated COCO person subset\"\"\"\n",
                "    coco_person_dir = DATASETS_DIR / 'coco_person'\n",
                "    \n",
                "    # Try to get person detection from Roboflow\n",
                "    try:\n",
                "        print(\"\\nüì• Downloading COCO Person subset...\")\n",
                "        project = rf.workspace(\"microsoft\").project(\"coco\")\n",
                "        dataset = project.version(\"1\").download(\n",
                "            \"yolov8\",\n",
                "            location=str(coco_person_dir)\n",
                "        )\n",
                "        print(\"‚úÖ Downloaded COCO dataset\")\n",
                "        return True\n",
                "    except:\n",
                "        print(\"‚ö†Ô∏è COCO download failed, using Roboflow person dataset instead\")\n",
                "        return False\n",
                "\n",
                "# Try to download, but don't fail if it doesn't work\n",
                "# We already have person from 'roboflow-100/people-detection-general'\n",
                "download_coco_person_subset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Merge Datasets with Unified Class IDs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remap_labels(label_file, old_classes, class_mapping, unified_classes):\n",
                "    \"\"\"Remap class IDs in a YOLO label file to unified class IDs\"\"\"\n",
                "    if not os.path.exists(label_file):\n",
                "        return 0\n",
                "    \n",
                "    with open(label_file, 'r') as f:\n",
                "        lines = f.readlines()\n",
                "    \n",
                "    new_lines = []\n",
                "    remapped_count = 0\n",
                "    \n",
                "    for line in lines:\n",
                "        parts = line.strip().split()\n",
                "        if len(parts) >= 5:\n",
                "            old_class_id = int(parts[0])\n",
                "            if old_class_id < len(old_classes):\n",
                "                old_class_name = old_classes[old_class_id]\n",
                "                # Map to unified class name\n",
                "                unified_name = class_mapping.get(old_class_name, None)\n",
                "                if unified_name and unified_name in unified_classes:\n",
                "                    new_class_id = unified_classes.index(unified_name)\n",
                "                    parts[0] = str(new_class_id)\n",
                "                    new_lines.append(' '.join(parts) + '\\n')\n",
                "                    remapped_count += 1\n",
                "    \n",
                "    with open(label_file, 'w') as f:\n",
                "        f.writelines(new_lines)\n",
                "    \n",
                "    return remapped_count\n",
                "\n",
                "def get_dataset_classes(dataset_path):\n",
                "    \"\"\"Read classes from dataset YAML\"\"\"\n",
                "    yaml_file = dataset_path / 'data.yaml'\n",
                "    if yaml_file.exists():\n",
                "        with open(yaml_file, 'r') as f:\n",
                "            data = yaml.safe_load(f)\n",
                "            names = data.get('names', [])\n",
                "            if isinstance(names, dict):\n",
                "                return [names[i] for i in sorted(names.keys())]\n",
                "            return names\n",
                "    return []\n",
                "\n",
                "print(\"‚úÖ Utility functions ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def merge_datasets():\n",
                "    \"\"\"Merge all downloaded datasets into a unified dataset\"\"\"\n",
                "    \n",
                "    # Create merged directory structure\n",
                "    for split in ['train', 'valid', 'test']:\n",
                "        (MERGED_DIR / split / 'images').mkdir(parents=True, exist_ok=True)\n",
                "        (MERGED_DIR / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    stats = {\n",
                "        'total_images': {'train': 0, 'valid': 0, 'test': 0},\n",
                "        'per_class': {cls: 0 for cls in UNIFIED_CLASSES},\n",
                "        'per_dataset': {}\n",
                "    }\n",
                "    \n",
                "    for dataset_name, config in DATASETS.items():\n",
                "        dataset_path = DATASETS_DIR / dataset_name\n",
                "        \n",
                "        # Find the actual dataset directory (sometimes nested)\n",
                "        for subdir in dataset_path.rglob('data.yaml'):\n",
                "            dataset_path = subdir.parent\n",
                "            break\n",
                "        \n",
                "        if not dataset_path.exists():\n",
                "            print(f\"‚ö†Ô∏è {dataset_name} not found, skipping...\")\n",
                "            continue\n",
                "        \n",
                "        # Get original classes\n",
                "        old_classes = get_dataset_classes(dataset_path)\n",
                "        print(f\"\\nüìÇ {dataset_name}: {old_classes}\")\n",
                "        \n",
                "        dataset_count = 0\n",
                "        \n",
                "        for split in ['train', 'valid', 'test']:\n",
                "            # Try different possible paths\n",
                "            src_images = None\n",
                "            for img_subdir in ['images', '']:\n",
                "                test_path = dataset_path / split / img_subdir if img_subdir else dataset_path / split\n",
                "                if test_path.exists():\n",
                "                    imgs = list(test_path.glob('*.jpg')) + list(test_path.glob('*.png'))\n",
                "                    if imgs:\n",
                "                        src_images = test_path\n",
                "                        break\n",
                "            \n",
                "            if not src_images:\n",
                "                continue\n",
                "            \n",
                "            # Find labels directory\n",
                "            label_dir = None\n",
                "            for lbl_subdir in ['labels', '']:\n",
                "                test_path = dataset_path / split / lbl_subdir if lbl_subdir else src_images.parent / 'labels'\n",
                "                if test_path.exists():\n",
                "                    label_dir = test_path\n",
                "                    break\n",
                "            \n",
                "            # Copy images and remap labels\n",
                "            for img_file in list(src_images.glob('*.jpg')) + list(src_images.glob('*.png')):\n",
                "                # Create unique filename\n",
                "                new_name = f\"{dataset_name}_{img_file.name}\"\n",
                "                \n",
                "                # Copy image\n",
                "                dst_img = MERGED_DIR / split / 'images' / new_name\n",
                "                shutil.copy(img_file, dst_img)\n",
                "                \n",
                "                # Copy and remap label\n",
                "                if label_dir:\n",
                "                    label_file = label_dir / (img_file.stem + '.txt')\n",
                "                    if label_file.exists():\n",
                "                        dst_label = MERGED_DIR / split / 'labels' / (new_name.rsplit('.', 1)[0] + '.txt')\n",
                "                        shutil.copy(label_file, dst_label)\n",
                "                        remap_labels(dst_label, old_classes, config['class_mapping'], UNIFIED_CLASSES)\n",
                "                \n",
                "                stats['total_images'][split] += 1\n",
                "                dataset_count += 1\n",
                "        \n",
                "        stats['per_dataset'][dataset_name] = dataset_count\n",
                "        print(f\"   Added {dataset_count} images\")\n",
                "    \n",
                "    # Create unified data.yaml\n",
                "    data_yaml = {\n",
                "        'path': str(MERGED_DIR),\n",
                "        'train': 'train/images',\n",
                "        'val': 'valid/images',\n",
                "        'test': 'test/images',\n",
                "        'names': {i: name for i, name in enumerate(UNIFIED_CLASSES)},\n",
                "        'nc': len(UNIFIED_CLASSES)\n",
                "    }\n",
                "    \n",
                "    with open(MERGED_DIR / 'data.yaml', 'w') as f:\n",
                "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
                "    \n",
                "    print(f\"\\n\" + \"=\"*50)\n",
                "    print(\"MERGED DATASET SUMMARY\")\n",
                "    print(\"=\"*50)\n",
                "    print(f\"Train: {stats['total_images']['train']} images\")\n",
                "    print(f\"Valid: {stats['total_images']['valid']} images\")\n",
                "    print(f\"Test:  {stats['total_images']['test']} images\")\n",
                "    print(f\"Total: {sum(stats['total_images'].values())} images\")\n",
                "    print(f\"\\nClasses: {UNIFIED_CLASSES}\")\n",
                "    print(f\"\\nPer-dataset breakdown:\")\n",
                "    for ds, count in stats['per_dataset'].items():\n",
                "        print(f\"   {ds}: {count} images\")\n",
                "    \n",
                "    return MERGED_DIR / 'data.yaml'\n",
                "\n",
                "# Merge all datasets\n",
                "data_yaml_path = merge_datasets()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Train Unified YOLO11n Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Training Configuration { display-mode: \"form\" }\n",
                "\n",
                "# ============================================\n",
                "# üéØ YOLO11n - Recommended for Jetson Orin Nano\n",
                "# ============================================\n",
                "MODEL_SIZE = \"yolo11n\"  # @param [\"yolo11n\", \"yolo11s\", \"yolov8n\", \"yolov8s\"]\n",
                "EPOCHS = 100  # @param {type:\"slider\", min:50, max:300, step:10}\n",
                "IMAGE_SIZE = 640  # @param [416, 512, 640, 800]\n",
                "BATCH_SIZE = 16  # @param [8, 16, 32]\n",
                "PATIENCE = 25  # @param {type:\"slider\", min:10, max:50, step:5}\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"TRAINING CONFIGURATION\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Model: {MODEL_SIZE}\")\n",
                "print(f\"Classes: {UNIFIED_CLASSES}\")\n",
                "print(f\"Epochs: {EPOCHS}\")\n",
                "print(f\"Image Size: {IMAGE_SIZE}\")\n",
                "print(f\"Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"Early Stop Patience: {PATIENCE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pre-trained YOLO11n model\n",
                "print(f\"\\nüì¶ Loading {MODEL_SIZE}...\")\n",
                "model = YOLO(f'{MODEL_SIZE}.pt')\n",
                "\n",
                "# Train on merged dataset\n",
                "# Settings aligned with ProFSAM-Fire-Detector training approach\n",
                "print(f\"\\nüöÄ Starting training...\")\n",
                "print(f\"   This will take 1-3 hours depending on dataset size\")\n",
                "\n",
                "results = model.train(\n",
                "    data=str(data_yaml_path),\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMAGE_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    patience=PATIENCE,\n",
                "    device=0,\n",
                "    workers=4,\n",
                "    project=str(MODELS_DIR),\n",
                "    name='petrol_pump_unified',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    \n",
                "    # Optimizer settings (aligned with ProFSAM-Fire-Detector)\n",
                "    optimizer='AdamW',\n",
                "    lr0=0.001,\n",
                "    lrf=0.01,\n",
                "    momentum=0.937,\n",
                "    weight_decay=0.0005,\n",
                "    warmup_epochs=3,\n",
                "    warmup_momentum=0.8,\n",
                "    \n",
                "    # Loss weights\n",
                "    box=7.5,\n",
                "    cls=0.5,\n",
                "    \n",
                "    # Augmentation\n",
                "    hsv_h=0.015,\n",
                "    hsv_s=0.7,\n",
                "    hsv_v=0.4,\n",
                "    degrees=0.0,\n",
                "    translate=0.1,\n",
                "    scale=0.5,\n",
                "    shear=0.0,\n",
                "    flipud=0.0,\n",
                "    fliplr=0.5,\n",
                "    mosaic=1.0,\n",
                "    mixup=0.15,\n",
                "    copy_paste=0.0,\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Evaluate Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model and validate\n",
                "best_model_path = MODELS_DIR / 'petrol_pump_unified' / 'weights' / 'best.pt'\n",
                "model = YOLO(str(best_model_path))\n",
                "\n",
                "# Run validation on test set\n",
                "metrics = model.val(data=str(data_yaml_path), split='test')\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"MODEL PERFORMANCE\")\n",
                "print(\"=\"*50)\n",
                "print(f\"mAP50:     {metrics.box.map50:.4f}\")\n",
                "print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
                "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
                "print(f\"Recall:    {metrics.box.mr:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class performance\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PER-CLASS PERFORMANCE\")\n",
                "print(\"=\"*50)\n",
                "for i, class_name in enumerate(UNIFIED_CLASSES):\n",
                "    if i < len(metrics.box.ap50):\n",
                "        ap = metrics.box.ap50[i]\n",
                "        status = \"‚úÖ\" if ap > 0.7 else \"‚ö†Ô∏è\" if ap > 0.5 else \"‚ùå\"\n",
                "        print(f\"{status} {class_name:12s}: AP50={ap:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Export for Jetson Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to multiple formats\n",
                "print(\"\\nüì¶ Exporting model for deployment...\")\n",
                "\n",
                "# ONNX export (universal, works with ONNX Runtime)\n",
                "onnx_path = model.export(\n",
                "    format='onnx',\n",
                "    imgsz=IMAGE_SIZE,\n",
                "    dynamic=True,\n",
                "    simplify=True\n",
                ")\n",
                "print(f\"‚úÖ ONNX: {onnx_path}\")\n",
                "\n",
                "# TensorRT (best done on Jetson, but try here)\n",
                "try:\n",
                "    engine_path = model.export(\n",
                "        format='engine',\n",
                "        imgsz=IMAGE_SIZE,\n",
                "        half=True\n",
                "    )\n",
                "    print(f\"‚úÖ TensorRT: {engine_path}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è TensorRT skipped (export on Jetson for best results)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare output package\n",
                "OUTPUT_DIR = Path('/content/petrol_pump_model')\n",
                "OUTPUT_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "# Copy model files\n",
                "shutil.copy(best_model_path, OUTPUT_DIR / 'petrol_pump_yolo11n.pt')\n",
                "\n",
                "# Copy ONNX if exists\n",
                "onnx_file = best_model_path.with_suffix('.onnx')\n",
                "if onnx_file.exists():\n",
                "    shutil.copy(onnx_file, OUTPUT_DIR / 'petrol_pump_yolo11n.onnx')\n",
                "\n",
                "# Create labels file\n",
                "with open(OUTPUT_DIR / 'labels.txt', 'w') as f:\n",
                "    for i, name in enumerate(UNIFIED_CLASSES):\n",
                "        f.write(f\"{i}: {name}\\n\")\n",
                "\n",
                "# Create usage guide\n",
                "usage_guide = f\"\"\"\n",
                "# Petrol Pump Unified YOLO11n Model\n",
                "\n",
                "## Classes:\n",
                "0: person     - Customer/employee detection\n",
                "1: fire       - Fire/flame detection (CRITICAL)\n",
                "2: smoke      - Smoke detection (early warning)\n",
                "3: violence   - Fighting/violence detection\n",
                "4: cigarette  - Smoking detection (CRITICAL at petrol pump)\n",
                "\n",
                "## Usage with Ultralytics:\n",
                "```python\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Load model\n",
                "model = YOLO('petrol_pump_yolo11n.pt')\n",
                "\n",
                "# Run on image\n",
                "results = model.predict('image.jpg', conf=0.5)\n",
                "\n",
                "# Run on video/RTSP stream\n",
                "results = model.predict('rtsp://camera_ip:554/stream', stream=True)\n",
                "\n",
                "# Process detections\n",
                "for result in results:\n",
                "    for box in result.boxes:\n",
                "        class_id = int(box.cls[0])\n",
                "        class_name = ['person', 'fire', 'smoke', 'violence', 'cigarette'][class_id]\n",
                "        confidence = float(box.conf[0])\n",
                "        \n",
                "        # ALERT on critical detections\n",
                "        if class_name in ['fire', 'smoke', 'cigarette']:\n",
                "            print(f\"üö® ALERT: {{class_name}} detected! ({{confidence:.0%}})\")\n",
                "```\n",
                "\n",
                "## Convert to TensorRT on Jetson:\n",
                "```bash\n",
                "yolo export model=petrol_pump_yolo11n.pt format=engine half=True\n",
                "```\n",
                "\n",
                "## Model Info:\n",
                "- Base: YOLO11n\n",
                "- Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\n",
                "- Classes: 5\n",
                "\"\"\"\n",
                "\n",
                "with open(OUTPUT_DIR / 'README.md', 'w') as f:\n",
                "    f.write(usage_guide)\n",
                "\n",
                "print(f\"\\n‚úÖ Model package ready: {OUTPUT_DIR}\")\n",
                "!ls -la {OUTPUT_DIR}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Test Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import random\n",
                "\n",
                "# Find test images\n",
                "test_images = list((MERGED_DIR / 'test' / 'images').glob('*.jpg'))\n",
                "if not test_images:\n",
                "    test_images = list((MERGED_DIR / 'valid' / 'images').glob('*.jpg'))\n",
                "\n",
                "if test_images:\n",
                "    # Test on multiple images\n",
                "    sample_images = random.sample(test_images, min(4, len(test_images)))\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for idx, img_path in enumerate(sample_images):\n",
                "        results = model.predict(str(img_path), conf=0.3, verbose=False)\n",
                "        result_img = results[0].plot()\n",
                "        \n",
                "        axes[idx].imshow(result_img[:, :, ::-1])\n",
                "        axes[idx].axis('off')\n",
                "        \n",
                "        # Get detection summary\n",
                "        detections = []\n",
                "        for box in results[0].boxes:\n",
                "            cls_id = int(box.cls[0])\n",
                "            detections.append(UNIFIED_CLASSES[cls_id])\n",
                "        axes[idx].set_title(f\"Detected: {', '.join(set(detections)) if detections else 'None'}\")\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(OUTPUT_DIR / 'sample_detections.png', dpi=150)\n",
                "    plt.show()\n",
                "    print(\"\\n‚úÖ Sample detections saved\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No test images found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Download Model Package"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create downloadable zip\n",
                "!cd /content && zip -r petrol_pump_yolo11n_complete.zip petrol_pump_model/\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"DOWNLOAD PACKAGE READY\")\n",
                "print(\"=\"*50)\n",
                "print(\"Contents:\")\n",
                "print(\"  üì¶ petrol_pump_yolo11n.pt    - PyTorch model\")\n",
                "print(\"  üì¶ petrol_pump_yolo11n.onnx  - ONNX model\")\n",
                "print(\"  üìÑ labels.txt                - Class labels\")\n",
                "print(\"  üìÑ README.md                 - Usage guide\")\n",
                "print(\"  üñºÔ∏è sample_detections.png     - Test results\")\n",
                "\n",
                "# Download\n",
                "try:\n",
                "    from google.colab import files\n",
                "    files.download('/content/petrol_pump_yolo11n_complete.zip')\n",
                "except:\n",
                "    print(\"\\nüì• Download: /content/petrol_pump_yolo11n_complete.zip\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìä Summary\n",
                "\n",
                "### Model Details\n",
                "| Attribute | Value |\n",
                "|-----------|-------|\n",
                "| Base Model | YOLO11n |\n",
                "| Classes | person, fire, smoke, violence, cigarette |\n",
                "| Image Size | 640x640 |\n",
                "| Expected FPS (Jetson Orin) | 40-50 FPS |\n",
                "| Model Size | ~6 MB |\n",
                "\n",
                "### Data Sources\n",
                "| Class | Primary Dataset | Reference |\n",
                "|-------|-----------------|------------|\n",
                "| person | Roboflow people-detection | COCO-style |\n",
                "| fire/smoke | Roboflow fire-detection | Similar to FASDD (ProFSAM-Fire-Detector) |\n",
                "| violence | Roboflow violence | Similar to fight_detection_yolov8 |\n",
                "| cigarette | Roboflow smoker-detection | Custom |\n",
                "\n",
                "### Next Steps\n",
                "1. Deploy `.pt` or `.onnx` on Jetson\n",
                "2. Convert to TensorRT on device for max speed\n",
                "3. Fine-tune with your own petrol pump footage if needed"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}